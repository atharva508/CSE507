{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- load and prep image (grayscale, [B,C,H,W]) ----\n",
    "img_path = \"1657999067686 copy.jpeg\"  # or the full path to your image\n",
    "img = Image.open(img_path).convert(\"RGB\")  # grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.array(img)).float() / 255.0  # [H,W] in [0,1]\n",
    "x = x.unsqueeze(0) # [1,1,H,W]\n",
    "\n",
    "# ---- define 3x3 Sobel kernels ----\n",
    "kx = torch.tensor([[-2., 0., 1.],\n",
    "                   [-2., 0., 2.],\n",
    "                   [-1., 0., 1.]]).reshape(1,1,3,3)\n",
    "\n",
    "ky = torch.tensor([[-1., -2., -1.],\n",
    "                   [ 0.,  0.,  0.],\n",
    "                   [ 1.,  2.,  1.]]).reshape(1,1,3,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move kernels to same device as input\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "kx = kx.to(device)\n",
    "ky = ky.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 1, 3, 3], expected input[1, 800, 800, 3] to have 1 channels, but got 800 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---- convolution with padding=1 to keep size ----\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gx \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m gy \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(x, ky, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ---- gradient magnitude ----\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 1, 3, 3], expected input[1, 800, 800, 3] to have 1 channels, but got 800 channels instead"
     ]
    }
   ],
   "source": [
    "# ---- convolution with padding=1 to keep size ----\n",
    "gx = F.conv2d(x, kx, padding=1)\n",
    "gy = F.conv2d(x, ky, padding=1)\n",
    "\n",
    "# ---- gradient magnitude ----\n",
    "mag = gx+gy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved edges to edges_sobel.jpg\n"
     ]
    }
   ],
   "source": [
    "# ---- normalize to [0,255] and save ----\n",
    "m = mag.squeeze().detach().cpu().numpy()\n",
    "m = (m / (m.max() + 1e-8) * 255.0).astype(np.uint8)\n",
    "out = Image.fromarray(m)\n",
    "out.save(\"edges_sobel.jpg\")\n",
    "print(\"Saved edges to edges_sobel.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_k = torch.tensor([[0.,  1., 0.],\n",
    "                          [1., -4., 1.],\n",
    "                          [0.,  1., 0.]]).reshape(1,1,3,3).to(device)\n",
    "lap = F.conv2d(x, laplace_k, padding=1)\n",
    "m = lap.squeeze().abs().detach().cpu().numpy()\n",
    "m = (m / (m.max() + 1e-8) * 255.0).astype(np.uint8)\n",
    "Image.fromarray(m).save(\"edges_laplacian.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved smoothed image to smoothed_3x3.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# ---------- load RGB image -> [1,3,H,W] float in [0,1] ----------\n",
    "img_path = \"1657999067686 copy.jpeg\"  # or the full path to your image\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "x = torch.from_numpy(np.array(img)).float() / 255.0            # [H,W,3]\n",
    "x = x.permute(2, 0, 1).unsqueeze(0)                            # [1,3,H,W]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "\n",
    "# ---------- choose one 3×3 smoothing kernel (sums to 1.0) ----------\n",
    "# Box blur (mean filter)\n",
    "box = torch.tensor([[1., 1., 1.],\n",
    "                    [1., 1., 1.],\n",
    "                    [1., 1., 1.]]) / 9.0\n",
    "\n",
    "# Gaussian blur (sigma≈1)\n",
    "gauss = torch.tensor([[1., 2., 1.],\n",
    "                      [2., 4., 2.],\n",
    "                      [1., 2., 1.]]) / 16.0\n",
    "\n",
    "K = gauss  # <- switch to `box` if you want mean blur\n",
    "\n",
    "# Repeat kernel per channel and move to device\n",
    "K3 = K.view(1, 1, 3, 3).repeat(3, 1, 3, 3).to(device)  # [out=3, in_per_group=1, 3,3]\n",
    "\n",
    "# ---------- reflect-pad to avoid dark borders, then grouped conv ----------\n",
    "# (conv2d doesn't support reflect directly; we pad first then use padding=0)\n",
    "x_pad = F.pad(x, pad=(1, 1, 1, 1), mode=\"reflect\")  # left, right, top, bottom\n",
    "y = F.conv2d(x_pad, K3, padding=0, groups=3)        # [1,3,H,W]\n",
    "\n",
    "# ---------- save result ----------\n",
    "y_np = (y.squeeze(0).clamp(0, 1) * 255.0).byte().permute(1, 2, 0).cpu().numpy()\n",
    "Image.fromarray(y_np).save(\"smoothed_3x3.jpg\")\n",
    "print(\"Saved smoothed image to smoothed_3x3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlhf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
